{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis for Interactive Segmentation Models\n",
    "\n",
    "This Jupyter Notebook processes and analyzes the evaluation results of different interactive segmentation models.\n",
    "It aggregates Dice Similarity Coefficients (DSC) across multiple folds and test sets to compare segmentation performance.\n",
    "\n",
    "### Workflow Overview\n",
    "1. **Data Loading**: Reads evaluation results from Excel files.\n",
    "2. **Aggregation**: Computes lesion-wise and global DSC statistics.\n",
    "3. **Visualization**: Generates summary plots using `plotly`.\n",
    "4. **Comparison**: Compares models across different evaluation modes.\n",
    "\n",
    "### Models Analyzed\n",
    "- **SW-FastEdit**\n",
    "- **DINs (Deep Interactive Networks)**\n",
    "- **SAM2 (Segment Anything Model 2)**\n",
    "\n",
    "Each model is evaluated in **lesion-wise corrective** and **global (scan-wise) corrective** modes using test sets 1 (high tumor burden) and 3 (low tumor burden).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results aggregation\n",
    "Read excel files containing interactive segmentation performance foe each case, fold, interaction scenario, and model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaged metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths and models\n",
    "base_path = \"/home/gkolokolnikov/PhD_project/nf_segmentation_interactive/NFInteractiveSegmentationBenchmarking/evaluation/results/metrics\"\n",
    "models = [\"SW-FastEdit\", \"DINs\", \"SAM2\"]\n",
    "modes = [\"lesion_wise_corrective\", \"global_corrective\"]\n",
    "test_sets = [\"TestSet_1\", \"TestSet_3\"]\n",
    "folds = [1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lesion_wise_metrics(model, test_set, folds):\n",
    "    \"\"\"\n",
    "    Processes lesion-wise DSC (Dice Similarity Coefficient) metrics for a given model across multiple folds.\n",
    "    \n",
    "    This function reads lesion-wise and global DSC values from Excel files stored in experiment folders, \n",
    "    aggregates them across folds, and computes the mean and standard deviation for each case.\n",
    "    \n",
    "    Args:\n",
    "        model (str): The name of the model being analyzed (e.g., \"DINs\", \"SAM2\").\n",
    "        test_set (str): Identifier for the test dataset (e.g., \"TestSet_1\").\n",
    "        folds (list): List of fold numbers to process (e.g., [1, 2, 3]).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the averaged lesion-wise and global DSC metrics across all folds.\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\">>> Processing lesion-wise mode metrics across folds...\")\n",
    "    case_metrics = {}\n",
    "\n",
    "    # Step 1: Collect metrics across folds for each case\n",
    "    for fold in folds:\n",
    "        folder_path = os.path.join(base_path, model, \"lesion_wise_corrective\", test_set, f\"fold_{fold}\")\n",
    "\n",
    "        for case in tqdm(os.listdir(folder_path)):\n",
    "            lesion_file = os.path.join(folder_path, case, \"lesion_metrics.xlsx\")\n",
    "            global_file_1 = os.path.join(folder_path, case, \"global_metrics_after_single_interaction.xlsx\")\n",
    "            global_file_all = os.path.join(folder_path, case, \"global_metrics.xlsx\")\n",
    "\n",
    "            # Initialize case entry if not already present\n",
    "            if case not in case_metrics:\n",
    "                case_metrics[case] = {\n",
    "                    'Lesion DSC after 1 interaction': [],\n",
    "                    'Lesion DSC after 3 interactions': [],\n",
    "                    'Global DSC after 1 interaction': [],\n",
    "                    'Global DSC after all interactions': []\n",
    "                }\n",
    "\n",
    "            # Read lesion DSC for the 1st and 3rd interactions\n",
    "            if os.path.exists(lesion_file):\n",
    "                lesion_df = pd.read_excel(lesion_file)\n",
    "                if len(lesion_df) >= 3:\n",
    "                    case_metrics[case]['Lesion DSC after 1 interaction'].append(lesion_df.iloc[1].values.mean())  # First interaction\n",
    "                    case_metrics[case]['Lesion DSC after 3 interactions'].append(lesion_df.iloc[2].values.mean())  # Third interaction\n",
    "                elif len(lesion_df) >= 1:\n",
    "                    case_metrics[case]['Lesion DSC after 1 interaction'].append(lesion_df.iloc[1].values.mean())\n",
    "                    case_metrics[case]['Lesion DSC after 3 interactions'].append(lesion_df.iloc[-1].values.mean())  # Take last if <3\n",
    "\n",
    "            # Read global DSC for 1 and all interactions\n",
    "            if os.path.exists(global_file_1):\n",
    "                global_df_1 = pd.read_excel(global_file_1)\n",
    "                case_metrics[case]['Global DSC after 1 interaction'].append(global_df_1.iloc[1]['dsc_global'])  # After 1 interaction\n",
    "\n",
    "            if os.path.exists(global_file_all):\n",
    "                global_df_all = pd.read_excel(global_file_all)\n",
    "                case_metrics[case]['Global DSC after all interactions'].append(global_df_all.iloc[1]['dsc_global'])  # After all interactions\n",
    "\n",
    "    \n",
    "    # Step 2: Compute mean and std for each case across folds\n",
    "    aggregated_results = []\n",
    "    for case, metrics in case_metrics.items():\n",
    "        aggregated_results.append({\n",
    "            'Lesion DSC after 1 interaction (mean)': np.mean(metrics['Lesion DSC after 1 interaction']) if metrics['Lesion DSC after 1 interaction'] else None,\n",
    "            'Lesion DSC after 1 interaction (std)': np.std(metrics['Lesion DSC after 1 interaction']) if metrics['Lesion DSC after 1 interaction'] else None,\n",
    "            'Lesion DSC after 3 interactions (mean)': np.mean(metrics['Lesion DSC after 3 interactions']) if metrics['Lesion DSC after 3 interactions'] else None,\n",
    "            'Lesion DSC after 3 interactions (std)': np.std(metrics['Lesion DSC after 3 interactions']) if metrics['Lesion DSC after 3 interactions'] else None,\n",
    "            'Global DSC after 1 interaction (mean)': np.mean(metrics['Global DSC after 1 interaction']) if metrics['Global DSC after 1 interaction'] else None,\n",
    "            'Global DSC after 1 interaction (std)': np.std(metrics['Global DSC after 1 interaction']) if metrics['Global DSC after 1 interaction'] else None,\n",
    "            'Global DSC after all interactions (mean)': np.mean(metrics['Global DSC after all interactions']) if metrics['Global DSC after all interactions'] else None,\n",
    "            'Global DSC after all interactions (std)': np.std(metrics['Global DSC after all interactions']) if metrics['Global DSC after all interactions'] else None,\n",
    "        })\n",
    "    \n",
    "    # Step 3: Compute overall average results\n",
    "    aggregated_results_pd = pd.DataFrame(aggregated_results).mean()\n",
    "    averaged_aggregated_results = {\n",
    "        'Model': model,\n",
    "        'TestSet': test_set,\n",
    "    }\n",
    "    for key in aggregated_results_pd.keys():\n",
    "        averaged_aggregated_results[key] = aggregated_results_pd[key]\n",
    "\n",
    "    print(\">>> Finished processing lesion-wise mode metrics.\")\n",
    "    return averaged_aggregated_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_global_metrics(model, test_set, folds):\n",
    "    \"\"\"\n",
    "    Processes global DSC (Dice Similarity Coefficient) metrics for a given model across multiple folds.\n",
    "    \n",
    "    This function reads global DSC values from Excel files stored in experiment folders, aggregates them \n",
    "    across folds, and computes the mean and standard deviation for each case.\n",
    "    \n",
    "    Args:\n",
    "        model (str): The name of the model being analyzed (e.g., \"DINs\", \"SAM2\").\n",
    "        test_set (str): Identifier for the test dataset (e.g., \"TestSet_1\").\n",
    "        folds (list): List of fold numbers to process (e.g., [1, 2, 3]).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the averaged global DSC metrics across all folds.\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\">>> Processing global mode metrics across folds...\")\n",
    "    case_metrics = {}\n",
    "\n",
    "    # Step 1: Collect metrics across folds for each case\n",
    "    for fold in folds:\n",
    "        folder_path = os.path.join(base_path, model, \"global_corrective\", test_set, f\"fold_{fold}\")\n",
    "\n",
    "        for case in tqdm(os.listdir(folder_path)):\n",
    "            global_file = os.path.join(folder_path, case, \"lesion_metrics.xlsx\")\n",
    "\n",
    "            # Initialize case entry if not already present\n",
    "            if case not in case_metrics:\n",
    "                case_metrics[case] = {\n",
    "                    'Global DSC after 1 interaction': [],\n",
    "                    'Global DSC after 3 interactions': [],\n",
    "                    'Global DSC after 20 interactions': [],\n",
    "                    'Global DSC after 60 interactions': []\n",
    "                }\n",
    "\n",
    "            # Process global metrics if file exists\n",
    "            if os.path.exists(global_file):\n",
    "                global_df = pd.read_excel(global_file)\n",
    "                \n",
    "                if len(global_df) > 1:\n",
    "                    case_metrics[case]['Global DSC after 1 interaction'].append(global_df.iloc[1].values.mean())  # After 1 interaction\n",
    "                if len(global_df) > 3:\n",
    "                    case_metrics[case]['Global DSC after 3 interactions'].append(global_df.iloc[3].values.mean())  # After 3 interactions\n",
    "                if len(global_df) > 20:\n",
    "                    case_metrics[case]['Global DSC after 20 interactions'].append(global_df.iloc[20].values.mean())  # After 20 interactions\n",
    "                if len(global_df) > 60:\n",
    "                    case_metrics[case]['Global DSC after 60 interactions'].append(global_df.iloc[60].values.mean())  # After 60 interactions\n",
    "\n",
    "    # Step 2: Compute mean and std for each case across folds\n",
    "    aggregated_results = []\n",
    "    for case, metrics in case_metrics.items():\n",
    "        aggregated_results.append({\n",
    "            'Global DSC after 1 interaction (mean)': np.mean(metrics['Global DSC after 1 interaction']) if metrics['Global DSC after 1 interaction'] else None,\n",
    "            'Global DSC after 1 interaction (std)': np.std(metrics['Global DSC after 1 interaction']) if metrics['Global DSC after 1 interaction'] else None,\n",
    "            'Global DSC after 3 interactions (mean)': np.mean(metrics['Global DSC after 3 interactions']) if metrics['Global DSC after 3 interactions'] else None,\n",
    "            'Global DSC after 3 interactions (std)': np.std(metrics['Global DSC after 3 interactions']) if metrics['Global DSC after 3 interactions'] else None,\n",
    "            'Global DSC after 20 interactions (mean)': np.mean(metrics['Global DSC after 20 interactions']) if metrics['Global DSC after 20 interactions'] else None,\n",
    "            'Global DSC after 20 interactions (std)': np.std(metrics['Global DSC after 20 interactions']) if metrics['Global DSC after 20 interactions'] else None,\n",
    "            'Global DSC after 60 interactions (mean)': np.mean(metrics['Global DSC after 60 interactions']) if metrics['Global DSC after 60 interactions'] else None,\n",
    "            'Global DSC after 60 interactions (std)': np.std(metrics['Global DSC after 60 interactions']) if metrics['Global DSC after 60 interactions'] else None,\n",
    "        })\n",
    "    \n",
    "    # Step 3: Compute overall average results\n",
    "    aggregated_results_pd = pd.DataFrame(aggregated_results).mean()\n",
    "    averaged_aggregated_results = {\n",
    "        'Model': model,\n",
    "        'TestSet': test_set,\n",
    "    }\n",
    "    for key in aggregated_results_pd.keys():\n",
    "        averaged_aggregated_results[key] = aggregated_results_pd[key]\n",
    "    print(\">>> Finished processing global mode metrics.\")\n",
    "    \n",
    "    return averaged_aggregated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all models and test sets\n",
    "# Lists to store aggregated results for lesion-wise and global metrics\n",
    "lesion_wise_results = []\n",
    "global_results = []\n",
    "\n",
    "# Loop through each model in the specified list\n",
    "for model in models:\n",
    "    print(f\"> Started processing data for model: {model}...\")\n",
    "    \n",
    "    # Loop through each test set\n",
    "    for test_set in test_sets:\n",
    "        print(f\">> Started processing set: {test_set}...\")\n",
    "        \n",
    "        # Compute lesion-wise and global metrics for the current model and test set\n",
    "        lesion_wise_results.append(process_lesion_wise_metrics(model, test_set, folds))\n",
    "        global_results.append(process_global_metrics(model, test_set, folds))\n",
    "        \n",
    "        print(\">> Finished processing.\")\n",
    "    print(\"> Finished processing.\")\n",
    "\n",
    "# Display the aggregated lesion-wise results\n",
    "lesion_wise_results\n",
    "\n",
    "# Convert results to Pandas DataFrame for further analysis\n",
    "lesion_wise_df = pd.DataFrame(lesion_wise_results)\n",
    "global_df = pd.DataFrame(global_results)\n",
    "\n",
    "# Save the aggregated results to Excel files\n",
    "lesion_wise_df.to_excel(f\"lesion_wise_results.xlsx\", index=False)\n",
    "global_df.to_excel(f\"global_results.xlsx\", index=False)\n",
    "\n",
    "print(\"Aggregation complete. Results saved to Excel.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results for the lesion-wise interaction scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_wise_df.loc[lesion_wise_df[\"TestSet\"] == \"TestSet_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_wise_df.loc[lesion_wise_df[\"TestSet\"] == \"TestSet_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results for the global scan-wise interaction scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.loc[global_df[\"TestSet\"] == \"TestSet_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.loc[global_df[\"TestSet\"] == \"TestSet_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per-case metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory containing evaluation results\n",
    "base_dir = \"/home/gkolokolnikov/PhD_project/nf_segmentation_interactive/NFInteractiveSegmentationBenchmarking/evaluation/results/metrics\"\n",
    "\n",
    "# Define the models and folds to process\n",
    "models = [\"DINs\", \"SW-FastEdit\", \"SAM2\"]\n",
    "folds = [\"fold_1\", \"fold_2\", \"fold_3\"]\n",
    "\n",
    "# Initialize lists to store results for lesion-wise and global DSC (Dice Similarity Coefficient) metrics\n",
    "lesion_wise_data = []\n",
    "global_data = []\n",
    "\n",
    "\n",
    "# Helper function to extract the last DSC value from a DataFrame\n",
    "def extract_last_dsc(file_path):\n",
    "    \"\"\"\n",
    "    Reads an Excel file and extracts the DSC (Dice Similarity Coefficient) value from the second row.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file containing global metrics.\n",
    "    \n",
    "    Returns:\n",
    "        float: The DSC value from the second row.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    return df.iloc[1]['dsc_global']\n",
    "\n",
    "\n",
    "# Process results for the global corrective approach\n",
    "print(\"Processing global corrective approach...\")\n",
    "for model in models:\n",
    "    print(f\"> Processing model: {model}\")\n",
    "    for test_set in os.listdir(os.path.join(base_dir, model, \"global_corrective\")):\n",
    "        print(f\">> Processing test_set: {test_set}\")\n",
    "        test_set_path = os.path.join(base_dir, model, \"global_corrective\", test_set)\n",
    "        for fold in folds:\n",
    "            print(f\">>> Processing fold {fold}\")\n",
    "            fold_path = os.path.join(test_set_path, fold)\n",
    "            if os.path.exists(fold_path):\n",
    "                for case in tqdm(os.listdir(fold_path)):\n",
    "                    case_path = os.path.join(fold_path, case)\n",
    "                    metrics_file = os.path.join(case_path, \"global_metrics.xlsx\")\n",
    "\n",
    "                    if os.path.exists(metrics_file):\n",
    "                        # Extract the last DSC value\n",
    "                        last_dsc = extract_last_dsc(metrics_file)\n",
    "\n",
    "                        # Append to the global data\n",
    "                        global_data.append({\n",
    "                            \"TestSet_Case\": f\"{test_set}_{case}\",\n",
    "                            f\"{model}_{fold}\": round(last_dsc, 2)\n",
    "                        })\n",
    "\n",
    "# Merge global DSC results into a structured dictionary\n",
    "merged_global_data = {}\n",
    "for entry in global_data:\n",
    "    test_set_case = entry[\"TestSet_Case\"]\n",
    "    if test_set_case not in merged_global_data:\n",
    "        merged_global_data[test_set_case] = {\"TestSet_Case\": test_set_case}\n",
    "    # Update the merged dictionary with the remaining keys and values\n",
    "    for key, value in entry.items():\n",
    "        if key != \"TestSet_Case\":\n",
    "            merged_global_data[test_set_case][key] = value\n",
    "\n",
    "# Convert merged global data to a Pandas DataFrame\n",
    "global_df = pd.DataFrame(merged_global_data.values())\n",
    "\n",
    "\n",
    "# Process results for the lesion-wise corrective approach\n",
    "print(\"Processing lesion-wise corrective approach...\")\n",
    "for model in models:\n",
    "    print(f\"> Processing model: {model}\")\n",
    "    for test_set in os.listdir(os.path.join(base_dir, model, \"lesion_wise_corrective\")):\n",
    "        print(f\">> Processing test_set: {test_set}\")\n",
    "        test_set_path = os.path.join(base_dir, model, \"lesion_wise_corrective\", test_set)\n",
    "        for fold in folds:\n",
    "            print(f\">>> Processing fold {fold}\")\n",
    "            fold_path = os.path.join(test_set_path, fold)\n",
    "            if os.path.exists(fold_path):\n",
    "                for case in tqdm(os.listdir(fold_path)):\n",
    "                    case_path = os.path.join(fold_path, case)\n",
    "                    metrics_file = os.path.join(case_path, \"global_metrics.xlsx\")\n",
    "\n",
    "                    if os.path.exists(metrics_file):\n",
    "                        # Extract the last DSC value\n",
    "                        last_dsc = extract_last_dsc(metrics_file)\n",
    "\n",
    "                        # Append to the global data\n",
    "                        lesion_wise_data.append({\n",
    "                            \"TestSet_Case\": f\"{test_set}_{case}\",\n",
    "                            f\"{model} {fold}\": round(last_dsc, 2)\n",
    "                        })\n",
    "\n",
    "# Merge lesion-wise DSC results into a structured dictionary\n",
    "merged_lesion_wise = {}\n",
    "\n",
    "for entry in lesion_wise_data:\n",
    "    test_set_case = entry[\"TestSet_Case\"]\n",
    "    if test_set_case not in merged_lesion_wise:\n",
    "        merged_lesion_wise[test_set_case] = {\"TestSet_Case\": test_set_case}\n",
    "    # Update the merged dictionary with the remaining keys and values\n",
    "    for key, value in entry.items():\n",
    "        if key != \"TestSet_Case\":\n",
    "            merged_lesion_wise[test_set_case][key] = value\n",
    "\n",
    "# Convert merged_data to a pandas DataFrame\n",
    "lesion_wise_df = pd.DataFrame(merged_lesion_wise.values())\n",
    "\n",
    "# Save results to Excel files\n",
    "lesion_wise_df.to_excel(\"lesion_wise_corrective_all_cases.xlsx\", index=False)\n",
    "global_df.to_excel(\"global_corrective_all_cases.xlsx\", index=False)\n",
    "\n",
    "print(\"Excel files created: lesion_wise_corrective_all_cases.xlsx and global_corrective_all_cases.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results visualization\n",
    "Show how the performance changed with increasing the number of interaction points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per-lesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size_value = 16\n",
    "scale = 2\n",
    "width = 350\n",
    "height = 450\n",
    "pos_y = -0.2\n",
    "\n",
    "# Load the data\n",
    "file_path = 'lesion_wise_results.xlsx'  # Replace with your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filter data for TestSet_1\n",
    "df_testset1 = df[df['TestSet'] == 'TestSet_1']\n",
    "\n",
    "# Extract data for each model\n",
    "models = ['DINs', 'SW-FastEdit', 'SAM2']\n",
    "traces = []\n",
    "\n",
    "# Define line styles and colors for publication quality\n",
    "line_styles = ['solid', 'dash', 'dot']\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_data = df_testset1[df_testset1['Model'] == model]\n",
    "\n",
    "    x = [1, 3]  # Interactions: 1 and 3\n",
    "    y = [\n",
    "        model_data['Lesion DSC after 1 interaction (mean)'].values[0],\n",
    "        model_data['Lesion DSC after 3 interactions (mean)'].values[0]\n",
    "    ]\n",
    "    error_y = [\n",
    "        model_data['Lesion DSC after 1 interaction (std)'].values[0],\n",
    "        model_data['Lesion DSC after 3 interactions (std)'].values[0]\n",
    "    ]\n",
    "\n",
    "    # Add a trace for the model\n",
    "    traces.append(go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode='lines+markers',\n",
    "        name=model,\n",
    "        line=dict(color=colors[i], dash=line_styles[i], width=2),\n",
    "        marker=dict(size=8, symbol='circle'),\n",
    "        error_y=dict(\n",
    "            type='data',\n",
    "            array=error_y,\n",
    "            visible=True,\n",
    "            thickness=1.5,\n",
    "            width=2\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(traces)\n",
    "\n",
    "# Update layout for research paper formatting\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(\n",
    "            text=\"(a)\",  # Title text\n",
    "            x=0.5,  # Center horizontally\n",
    "            y=pos_y,  # Position below the plot\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            showarrow=False,\n",
    "            font=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "        )\n",
    "    ],\n",
    "    xaxis=dict(\n",
    "        title=\"Number of Interactions\",\n",
    "        title_font=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "        tickvals=[0, 1, 2, 3, 4, 5],\n",
    "        range=[0.5, 3.5],  # Set x-axis range\n",
    "        tickfont=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Per-lesion Dice Similarity Score\",\n",
    "        title_font=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "        range=[0.0, 0.5],  # Set y-axis range\n",
    "        tickfont=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    # legend=dict(\n",
    "    #     title=dict(\n",
    "    #         text=\"Models\",\n",
    "    #         font=dict(family=\"Times New Roman\", size=14)  # Smaller font size for legend title\n",
    "    #     ),\n",
    "    #     font=dict(family=\"Times New Roman\", size=14),\n",
    "    #     orientation=\"v\",  # Vertical legend\n",
    "    #     x=1.02,  # Position legend outside the plot on the right\n",
    "    #     y=0.5,\n",
    "    #     xanchor=\"left\",\n",
    "    #     yanchor=\"middle\",\n",
    "    # ),\n",
    "    template=\"plotly\",\n",
    "    margin=dict(l=50, r=150, t=20, b=80),  # Adjust margins to fit legend\n",
    "    width=width,  # Set the width of the plot 300\n",
    "    height=height,  # Set the height of the plot for 1:1 aspect ratio 350\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"Per_lesion_DSC_vs_interactions.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per-scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = 'global_results.xlsx'  # Replace with your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filter data for TestSet_1\n",
    "df_testset1 = df[df['TestSet'] == 'TestSet_1']\n",
    "\n",
    "# Extract data for each model\n",
    "models = ['DINs', 'SW-FastEdit', 'SAM2']\n",
    "traces = []\n",
    "\n",
    "# Define line styles and colors for publication quality\n",
    "line_styles = ['solid', 'dash', 'dot']\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_data = df_testset1[df_testset1['Model'] == model]\n",
    "\n",
    "    x = [1, 3]  # Interactions: 1 and 3\n",
    "    y = [\n",
    "        model_data['Global DSC after 1 interaction (mean)'].values[0],\n",
    "        model_data['Global DSC after 3 interactions (mean)'].values[0]\n",
    "    ]\n",
    "    error_y = [\n",
    "        model_data['Global DSC after 1 interaction (std)'].values[0],\n",
    "        model_data['Global DSC after 3 interactions (std)'].values[0]\n",
    "    ]\n",
    "\n",
    "    # Add a trace for the model\n",
    "    traces.append(go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode='lines+markers',\n",
    "        name=model,\n",
    "        line=dict(color=colors[i], dash=line_styles[i], width=2),\n",
    "        marker=dict(size=8, symbol='circle'),\n",
    "        error_y=dict(\n",
    "            type='data',\n",
    "            array=error_y,\n",
    "            visible=True,\n",
    "            thickness=1.5,\n",
    "            width=2\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(traces)\n",
    "\n",
    "# Update layout for research paper formatting\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(\n",
    "            text=\"(b)\",  # Title text\n",
    "            x=0.5,  # Center horizontally\n",
    "            y=-0.2,  # Position below the plot\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            showarrow=False,\n",
    "            font=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "        )\n",
    "    ],\n",
    "    xaxis=dict(\n",
    "        title=\"Number of Interactions\",\n",
    "        title_font=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "        tickvals=[0, 1, 2, 3, 4, 5],\n",
    "        range=[0.5, 3.5],  # Set x-axis range\n",
    "        tickfont=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Per-scan Dice Similarity Score\",\n",
    "        title_font=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "        range=[0.0, 0.5],  # Set y-axis range\n",
    "        tickfont=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Models\",\n",
    "            font=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\")  # Smaller font size for legend title\n",
    "        ),\n",
    "        font=dict(family=\"Times New Roman\", size=font_size_value, color=\"black\"),\n",
    "        orientation=\"v\",  # Vertical legend\n",
    "        x=1.02,  # Position legend outside the plot on the right\n",
    "        y=0.5,\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"middle\",\n",
    "    ),\n",
    "    template=\"plotly\",\n",
    "    margin=dict(l=50, r=150, t=20, b=80),  # Adjust margins to fit legend\n",
    "    width=width,  # Set the width of the plot 300\n",
    "    height=height,  # Set the height of the plot for 1:1 aspect ratio 350\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.write_image(\"Per_scan_DSC_vs_interactions.png\", scale=scale)\n",
    "fig.write_image(\"Per_scan_DSC_vs_interactions.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_iseg_benchmark_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
